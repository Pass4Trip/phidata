from typing import Optional, List
from phi.agent import Agent
from phi.model.openai import OpenAIChat
from phi.tools.python import PythonTools
from agents.settings import agent_settings
import os
import logging
from dotenv import load_dotenv
from db.url import get_db_url
from phi.storage.agent.postgres import PgAgentStorage
from phi.agent import AgentMemory
from phi.memory.db.postgres import PgMemoryDb
from utils.colored_logging import get_colored_logger
import io
import sys
import re

# Importer les agents sp√©cialis√©s
from agents.web import get_web_searcher
from agents.api_knowledge import get_api_knowledge_agent
from agents.data_analysis import get_data_analysis_agent

# Charger les variables d'environnement
load_dotenv()

# Configuration du logger
logger = get_colored_logger('agents.main_router_agent', 'MainRouterAgent', level=logging.DEBUG)

db_url = get_db_url()

def clean_ansi_escape(text):
    """
    Nettoie les codes d'√©chappement ANSI d'une cha√Æne de caract√®res
    """
    # Expression r√©guli√®re pour supprimer les codes ANSI
    ansi_escape = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
    return ansi_escape.sub('', text)

def extract_response_content(text):
    """
    Extrait le contenu textuel de la r√©ponse de l'agent
    """
    # Nettoyer les codes ANSI
    clean_text = clean_ansi_escape(text)
    
    # Extraire le contenu entre "R√©sum√© :" et "Source :"
    resume_match = re.search(r'R√©sum√© :(.*?)Source :', clean_text, re.DOTALL)
    if resume_match:
        return resume_match.group(1).strip()
    
    # Si pas de r√©sum√©, retourner le texte nettoy√©
    return clean_text.strip()

def create_agent_team(
    user_id: Optional[str] = None,
    session_id: Optional[str] = None,
    debug_mode: bool = False
) -> Agent:
    """
    Cr√©er une √©quipe d'agents avec des r√¥les sp√©cifiques
    """
    # V√©rifier si la cl√© API est d√©finie
    if not os.getenv('OPENAI_API_KEY'):
        raise ValueError("La cl√© API OpenAI n'est pas d√©finie. Veuillez d√©finir OPENAI_API_KEY dans votre fichier .env.")

    # Configurer le logging en mode DEBUG
    logger.setLevel(logging.INFO)

    # R√©cup√©rer l'URL de base de donn√©es (optionnel)
    if db_url:
        logger.debug(f"URL de base de donn√©es configur√©e : {db_url}")

    # Cr√©er les agents sp√©cialis√©s
    web_agent = get_web_searcher(
        user_id=user_id, 
        session_id=session_id, 
        debug_mode=debug_mode
    )
    web_agent.name = "Web Research Agent"
    web_agent.role = "Rechercher des informations actuelles et pertinentes sur le web"

    api_knowledge_agent = get_api_knowledge_agent(
        user_id=user_id, 
        session_id=session_id, 
        debug_mode=debug_mode
    )
    api_knowledge_agent.name = "Knowledge API Agent"
    api_knowledge_agent.role = "Acc√©der et analyser des connaissances via des API sp√©cialis√©es"

    data_analysis_agent = get_data_analysis_agent(
        user_id=user_id, 
        session_id=session_id, 
        debug_mode=debug_mode
    )
    data_analysis_agent.name = "Data Analysis Agent"
    data_analysis_agent.role = "Effectuer des analyses approfondies et g√©n√©rer des insights √† partir de donn√©es"

    # Agent principal de routage et de coordination
    router_agent = Agent(
        name="Main Router Agent",
        role="Coordonner et router les requ√™tes entre les diff√©rents agents sp√©cialis√©s",
        model=OpenAIChat(
            id=agent_settings.gpt_4,
            max_tokens=agent_settings.default_max_completion_tokens,
            temperature=agent_settings.default_temperature,
        ),
        instructions=[
            "Analyser soigneusement chaque requ√™te utilisateur",
            "D√©terminer la meilleure strat√©gie d'utilisation des agents sp√©cialis√©s",
            "Coordonner les interactions entre les agents",
            "Compiler et synth√©tiser les r√©sultats des diff√©rents agents",
            "Fournir une r√©ponse claire et compl√®te",
        ],
        tools=[PythonTools()],
        show_tool_calls=True,
        markdown=True,
        stream=False  # D√©sactiver le streaming
    )
    logger.info("üîÄ Agent Routeur Principal pr√™t √† coordonner les requ√™tes")

    # Cr√©er l'√©quipe d'agents
    agent_team = Agent(
        name="Multi-Purpose Intelligence Team",
        team=[
            web_agent, 
            api_knowledge_agent, 
            data_analysis_agent, 
            router_agent
        ],
        instructions=[
            "Collaborer efficacement pour r√©soudre la requ√™te de l'utilisateur",
            "Chaque agent doit utiliser ses comp√©tences sp√©cifiques",
            "Partager les informations et les insights entre les agents",
            "√ätre transparent sur la source et la m√©thode d'obtention des informations",
        ],
        add_datetime_to_instructions=True,
        show_tool_calls=True,
        markdown=True,
        monitoring=True,
        debug_mode=debug_mode,
        storage=PgAgentStorage(table_name="multi_agent_team_sessions", db_url=db_url),
        memory=AgentMemory(
            db=PgMemoryDb(table_name="multi_agent_team_memory", db_url=db_url),
            create_user_memories=True,
            create_session_summary=True
        ),
    )

    return agent_team

def process_user_request(
    user_request: str, 
    user_id: Optional[str] = None, 
    session_id: Optional[str] = None, 
    debug_mode: bool = False
):
    """
    Traiter une requ√™te utilisateur avec l'√©quipe d'agents
    """
    try:
        agent_team = create_agent_team(
            user_id=user_id, 
            session_id=session_id, 
            debug_mode=debug_mode
        )
        
        # Ex√©cuter la requ√™te avec l'√©quipe d'agents
        response = agent_team.run(user_request, stream=False)
        
        # Log d√©taill√© du type de r√©ponse
        #logger.debug(f"Type de r√©ponse re√ßue : {type(response)}")
        #logger.debug(f"Contenu de la r√©ponse : {response}")
        
        # V√©rifier et convertir la r√©ponse
        if response is None:
            logger.warning("Aucune r√©ponse g√©n√©r√©e par l'agent.")
            return "Aucun r√©sultat n'a pu √™tre g√©n√©r√©."
        
        # Convertir la r√©ponse en cha√Æne lisible
        if isinstance(response, dict):
            # Log d√©taill√© du dictionnaire
            logger.debug(f"Cl√©s du dictionnaire : {list(response.keys())}")
            
            # Gestion sp√©cifique des r√©ponses de l'API Knowledge
            if response.get('status') == 'success':
                # Extraction des r√©sultats
                if 'results' in response:
                    results = response.get('results', [])
                    # Log du nombre de r√©sultats
                    logger.debug(f"Nombre de r√©sultats : {len(results)}")
                    
                    # Formater les r√©sultats en une liste de textes
                    formatted_results = "\n".join([
                        str(result.get('text', 'R√©sultat sans texte')) 
                        for result in results
                    ])
                    return formatted_results
                
                # Si pas de r√©sultats, mais autres informations
                if 'question' in response:
                    return str(response['question'])
                
                # Cas par d√©faut pour les dictionnaires
                return str(response)
            
            # Conversion g√©n√©rique pour d'autres types de dictionnaires
            return str(response)
        
        # Pour les autres types de r√©ponses
        return str(response)
    
    except Exception as e:
        logger.error(f"Erreur lors du traitement de la requ√™te : {e}")
        # Log de la trace compl√®te de l'erreur
        import traceback
        logger.error(traceback.format_exc())
        return f"Erreur : {str(e)}"

# Exemple d'utilisation
if __name__ == "__main__":
    test_request = "Trouve et analyse les derni√®res tendances de l'IA, avec des sources et des donn√©es"
    process_user_request(test_request, debug_mode=True)
