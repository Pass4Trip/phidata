from typing import Optional, Any, Dict, Callable
import os
import logging
from dotenv import load_dotenv
import json
import uuid
from datetime import datetime, timedelta
from datetime import datetime
from typing import Optional
import pika
import threading

from phi.agent import Agent, AgentMemory
from phi.model.openai import OpenAIChat
from phi.storage.agent.postgres import PgAgentStorage
from phi.memory.db.postgres import PgMemoryDb

from sqlalchemy import create_engine, Column, String, Text, DateTime
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from datetime import datetime
from sqlalchemy import text

import queue
from typing import Callable, Any, Optional
from datetime import datetime, timedelta

Base = declarative_base()

class UserProxyTask(Base):
    """
    Mod√®le SQLAlchemy pour la table userproxy_task_memories
    """
    __tablename__ = 'userproxy_task_memories'

    task_id = Column(String, primary_key=True, nullable=False)
    user_id = Column(String, nullable=False)
    task_state = Column(String, nullable=False)
    task_desc = Column(Text, nullable=True)
    task_create_on = Column(DateTime, default=datetime.now)
    task_closed_on = Column(DateTime, nullable=True)

def save_user_proxy_task(
    task_id: str, 
    user_id: str, 
    task_state: str, 
    task_desc: Optional[str] = None,
    task_create_on: Optional[datetime] = None,
    task_closed_on: Optional[datetime] = None
) -> bool:
    """
    Enregistre une t√¢che dans la table userproxy_task_memories.
    
    Args:
        task_id (str): Identifiant unique de la t√¢che
        user_id (str): Identifiant de l'utilisateur
        task_state (str): √âtat de la t√¢che
        task_desc (Optional[str]): Description de la t√¢che
        task_create_on (Optional[datetime]): Date de cr√©ation de la t√¢che
        task_closed_on (Optional[datetime]): Date de fermeture de la t√¢che
    
    Returns:
        bool: True si l'enregistrement a r√©ussi, False sinon
    """
    import logging
    from sqlalchemy.exc import SQLAlchemyError, IntegrityError
    
    logger = logging.getLogger('agents.user_proxy')
    
    # Validation des param√®tres d'entr√©e
    if not task_id or not user_id or not task_state:
        logger.error("Param√®tres invalides : task_id, user_id et task_state sont requis")
        return False
    
    try:
        # Cr√©er le moteur de base de donn√©es
        engine = create_engine(db_url, echo=False)
        
        # Cr√©er les tables si elles n'existent pas
        Base.metadata.create_all(engine)
        
        # Cr√©er une session
        Session = sessionmaker(bind=engine)
        session = Session()
        
        # Cr√©er l'objet t√¢che
        new_task = UserProxyTask(
            task_id=task_id,
            user_id=user_id,
            task_state=task_state,
            task_desc=task_desc,
            task_create_on=task_create_on or datetime.now(),
            task_closed_on=task_closed_on
        )
        
        # Ajouter et commiter la transaction
        session.add(new_task)
        session.commit()
        
        logger.info(f"T√¢che {task_id} enregistr√©e avec succ√®s pour l'utilisateur {user_id}")
        return True
    
    except IntegrityError as ie:
        logger.error(f"Erreur d'int√©grit√© lors de l'enregistrement de la t√¢che : {str(ie)}")
        session.rollback()
        return False
    
    except SQLAlchemyError as se:
        logger.error(f"Erreur SQLAlchemy lors de l'enregistrement de la t√¢che : {str(se)}")
        session.rollback()
        return False
    
    except Exception as e:
        logger.error(f"Erreur inattendue lors de l'enregistrement de la t√¢che : {str(e)}")
        return False
    
    finally:
        # Fermer la session
        if 'session' in locals():
            session.close()


# Charger les variables d'environnement
load_dotenv()

# Construction dynamique de l'URL de base de donn√©es PostgreSQL
def build_postgres_url() -> str:
    """
    Construire dynamiquement l'URL de connexion PostgreSQL √† partir des variables d'environnement
    
    Returns:
        str: URL de connexion PostgreSQL
    """
    # R√©cup√©rer les param√®tres de connexion depuis les variables d'environnement
    db_host = os.getenv('DB_HOST', 'vps-af24e24d.vps.ovh.net')
    db_port = os.getenv('DB_PORT', '30030')
    db_name = os.getenv('DB_NAME', 'myboun')
    db_user = os.getenv('DB_USER', 'p4t')
    db_password = os.getenv('DB_PASSWORD', '')
    db_schema = os.getenv('DB_SCHEMA', 'ai')
    
    # Construire l'URL de connexion PostgreSQL avec le sch√©ma
    db_url = f'postgresql+psycopg2://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}?options=-c%20search_path%3D{db_schema}'
    
    return db_url

# G√©n√©rer l'URL de base de donn√©es
db_url = build_postgres_url()

model_id = os.getenv('model_id', 'gpt-4o-mini')

# Configuration du logging
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)  # R√©duire le niveau de log
handler = logging.StreamHandler()
handler.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

agent_storage_file: str = "orchestrator_agent_sessions.db"


def get_user_preferences(
    query: str,
    user_id: str, 
    db_url: Optional[str] = None, 
    table_name: str = "user_proxy_memories"
) -> Dict[str, Any]:
    """
    R√©cup√®re les m√©moires d'un utilisateur √† partir de la m√©moire Phidata.
    
    Args:
        user_id (str): Identifiant de l'utilisateur
        db_url (Optional[str]): URL de connexion √† la base de donn√©es PostgreSQL
        table_name (str): Nom de la table de m√©moire
    
    Returns:
        List[str]: Liste des m√©moires de l'utilisateur
    """
    # Utiliser l'URL de base de donn√©es globale si non fournie
    if db_url is None:
        db_url = globals().get('db_url')
    
    if not db_url:
        logger.error("Aucune URL de base de donn√©es fournie.")
        return []
    
    try:
        # Cr√©er une m√©moire d'agent avec la base de donn√©es PostgreSQL
        agent_memory = AgentMemory(
            db=PgMemoryDb(
                table_name=table_name, 
                db_url=db_url
            ),
            # D√©finir l'ID utilisateur
            user_id=user_id
        )
        
        # Charger les m√©moires de l'utilisateur
        memories = agent_memory.db.read_memories(user_id=user_id)
        
        # Stocker les m√©moires utilisateur
        user_memories = []
        
        # Parcourir toutes les m√©moires
        for memory in memories:
            try:
                memory_content = None
                
                if isinstance(memory.memory, dict):
                    memory_content = memory.memory.get('memory')
                elif isinstance(memory.memory, str):
                    try:
                        memory_dict = json.loads(memory.memory)
                        memory_content = memory_dict.get('memory')
                    except json.JSONDecodeError:
                        memory_content = memory.memory
                else:
                    memory_content = str(memory.memory)
                
                if memory_content:
                    user_memories.append(memory_content)
            
            except Exception as e:
                logger.error(f"‚ùå Erreur lors du traitement de la m√©moire : {e}")
                pass
        
        logger.info(f"üìã Nombre de m√©moires extraites : {len(user_memories)}")
        
        return user_memories
    
    except Exception as e:
        logger.error(f"Erreur lors du chargement des m√©moires : {e}")
        return []


class UserTaskManager:
    """
    Gestionnaire avanc√© de t√¢ches utilisateur avec int√©gration Phidata
    """
    _instance = None
    _lock = threading.Lock()

    def __new__(cls):
        if not cls._instance:
            with cls._lock:
                if not cls._instance:
                    cls._instance = super().__new__(cls)
        return cls._instance

    def __init__(self):
        if not hasattr(self, 'initialized'):
            self.task_queues = {}
            self.active_tasks = {}
            self.logger = logging.getLogger('agents.task_manager')
            self.initialized = True

    def enqueue_task(
        self, 
        user_id: str, 
        task_function: Callable[[], Any],
        max_queue_size: int = 5,
        task_timeout: int = 600  # 10 minutes
    ) -> dict:
        """
        Ajouter une t√¢che √† la file d'un utilisateur
        """
        with self._lock:
            # Initialiser la file si n√©cessaire
            if user_id not in self.task_queues:
                self.task_queues[user_id] = queue.Queue(maxsize=max_queue_size)
            
            # V√©rifier la taille de la file
            if self.task_queues[user_id].full():
                self.logger.warning(f"File d'attente pleine pour {user_id}")
                return {
                    'status': 'error',
                    'message': 'Trop de t√¢ches en attente',
                    'code': 'QUEUE_FULL'
                }
            
            # G√©n√©rer un identifiant de t√¢che
            task_id = str(uuid.uuid4())
            
            # Pr√©parer les informations de la t√¢che
            task_info = {
                'task_id': task_id,
                'user_id': user_id,
                'status': 'queued',
                'created_at': datetime.now(),
                'timeout_at': datetime.now() + timedelta(seconds=task_timeout)
            }
            
            # Ajouter √† la file
            self.task_queues[user_id].put((task_info, task_function))
            
            # D√©marrer le traitement si pas de t√¢che active
            if user_id not in self.active_tasks:
                self._start_task_processing(user_id)
            
            return {
                'status': 'success',
                'task_id': task_id,
                'message': 'T√¢che en file d\'attente'
            }

    def _start_task_processing(self, user_id: str):
        """
        D√©marrer le traitement des t√¢ches pour un utilisateur
        """
        def task_processor():
            while True:
                try:
                    # R√©cup√©rer la prochaine t√¢che
                    with self._lock:
                        if self.task_queues[user_id].empty():
                            del self.active_tasks[user_id]
                            break
                        
                        task_info, task_function = self.task_queues[user_id].get()
                    
                    # V√©rifier le timeout
                    if datetime.now() > task_info['timeout_at']:
                        self.logger.warning(f"T√¢che {task_info['task_id']} expir√©e")
                        task_info['status'] = 'timeout'
                        continue
                    
                    # Ex√©cuter la t√¢che
                    try:
                        self.logger.info(f"D√©but de la t√¢che {task_info['task_id']}")
                        task_info['status'] = 'processing'
                        result = task_function()
                        task_info['status'] = 'completed'
                        task_info['result'] = result
                    except Exception as e:
                        self.logger.error(f"Erreur lors de l'ex√©cution de la t√¢che : {e}")
                        task_info['status'] = 'failed'
                        task_info['error'] = str(e)
                    
                    # Marquer la t√¢che comme trait√©e
                    self.task_queues[user_id].task_done()
                
                except Exception as e:
                    self.logger.critical(f"Erreur critique dans le processeur de t√¢ches : {e}")
                    break
        
        # D√©marrer le thread de traitement
        thread = threading.Thread(target=task_processor, daemon=True)
        thread.start()
        self.active_tasks[user_id] = thread

    def get_task_status(self, user_id: str, task_id: str) -> Optional[dict]:
        """
        R√©cup√©rer le statut d'une t√¢che
        """
        if user_id not in self.task_queues:
            return None
        
        for queue_item in list(self.task_queues[user_id].queue):
            if queue_item[0]['task_id'] == task_id:
                return queue_item[0]
        return None

# Singleton global pour le gestionnaire de t√¢ches
global_task_manager = UserTaskManager()


def send2RabbitMQ(
    query: str = "query text", 
    session_id: Optional[str] = None, 
    user_id: Optional[str] = None,
    date: Optional[str] = None
) -> str:
    """
    Envoie un message √† RabbitMQ avec gestion des erreurs et logging.
    
    :param query: Le message √† envoyer
    :param session_id: L'identifiant de session
    :param user_id: L'identifiant de l'utilisateur
    :return: Un message d√©crivant le r√©sultat de l'envoi
    """
    import pika
    import os
    import logging
    import json
    import uuid
    from datetime import datetime
    
    try:
        # Configuration par d√©faut RabbitMQ
        config = {
            'host': os.getenv('RABBITMQ_HOST', 'localhost'),
            'port': int(os.getenv('RABBITMQ_PORT', 5672)),
            'credentials': pika.PlainCredentials(
                os.getenv('RABBITMQ_USER', 'guest'),
                os.getenv('RABBITMQ_PASSWORD', 'guest')
            )
        }
        queue_name = 'test_user_proxy'
        
        # Nettoyer et s√©curiser les param√®tres
        query = query.strip() if query else "Message vide re√ßu"
   
        
        # Pr√©parer le message
        message = {
            'session_id': session_id,
            'user_id': user_id,
            'query': query,
            'status': 'in_progress',
            'timestamp': date
        }
        
        # √âtablir la connexion et envoyer
        with pika.BlockingConnection(pika.ConnectionParameters(**config)) as connection:
            channel = connection.channel()
            channel.queue_declare(queue=queue_name, durable=True)
            
            channel.basic_publish(
                exchange='',
                routing_key=queue_name,
                body=json.dumps(message).encode('utf-8'),
                properties=pika.BasicProperties(
                    delivery_mode=2,  # Message persistant
                    content_type='application/json'
                )
            )
            
            logger.info(f"Message envoy√© √† RabbitMQ sur la file {queue_name}")
            return f"Message envoy√© avec succ√®s sur la file {queue_name}"
    
    except Exception as e:
        error_msg = f"Erreur lors de l'envoi du message √† RabbitMQ : {str(e)}"
        logger.error(error_msg)
        return error_msg


def wait_for_task_completion(
    session_id: str, 
    timeout: int = 600,  # 10 minutes par d√©faut
    poll_interval: float = 0.5  # Intervalle de v√©rification en secondes
) -> str:
    """
    Attendre la compl√©tion d'une t√¢che via RabbitMQ.
    
    Args:
        session_id (str): Identifiant de session unique
        timeout (int): Temps maximum d'attente en secondes
        poll_interval (float): Intervalle entre chaque v√©rification
    
    Returns:
        str: R√©sultat de la t√¢che ou message d'erreur
    """

    import json
    import time
    import logging

    
    logger = logging.getLogger('agents.user_proxy')
    
    # Param√®tres de connexion RabbitMQ
    connection_params = pika.ConnectionParameters(
        host=os.getenv('RABBITMQ_HOST', 'localhost'),
        port=int(os.getenv('RABBITMQ_PORT', 5672)),
        credentials=pika.PlainCredentials(
            os.getenv('RABBITMQ_USER', 'guest'),
            os.getenv('RABBITMQ_PASSWORD', 'guest')
        )
    )
    
    # Noms des queues
    result_queue_name = 'queue_retour_orchestrator'
    chatbot_queue_name = 'queue_chatbot'
    
    try:
        logger.info(f" D√©marrage de wait_for_task_completion pour session {session_id}")
        logger.info(f" Param√®tres de connexion RabbitMQ : {connection_params}")
        
        # √âtablir la connexion
        with pika.BlockingConnection(connection_params) as connection:
            channel = connection.channel()
            
            # D√©clarer les queues si elles n'existent pas
            logger.info(f" D√©claration des queues : {result_queue_name}, {chatbot_queue_name}")
            channel.queue_declare(queue=result_queue_name, durable=True)
            channel.queue_declare(queue=chatbot_queue_name, durable=True)
            
            # Temps de d√©but
            start_time = time.time()
            
            logger.info(f" D√©but de la boucle d'attente. Timeout : {timeout} secondes")
            while (time.time() - start_time) < timeout:
                # R√©cup√©rer un message
                method_frame, properties, body = channel.basic_get(queue=result_queue_name)
                
                if method_frame is None:
                    # Pas de message, attendre un peu
                    logger.debug(f" Aucun message dans la queue {result_queue_name}. Attente...")
                    time.sleep(poll_interval)
                    continue
                
                try:
                    # D√©coder le message en supprimant les caract√®res de retour chariot et les espaces suppl√©mentaires
                    message_str = body.decode('utf-8').strip()
                    
                    logger.info(f" Message brut re√ßu : {message_str[:200]}...")
                    
                    # Nettoyer manuellement la cha√Æne JSON
                    message_str = message_str.replace('\r\n', '').replace('\n', '')
                    
                    # Ajouter des virgules manquantes si n√©cessaire
                    if message_str.startswith(' {'):
                        message_str = '{' + message_str[2:]
                    
                    # Tenter de d√©coder le JSON
                    message = json.loads(message_str)
                    
                    logger.info(f" Message JSON d√©cod√© : {json.dumps(message, indent=2)}")
                    
                    # V√©rifier si c'est le bon message
                    if (message.get('session_id') == session_id and 
                        message.get('status') == 'completed'):
                        
                        logger.info(f" Message correspondant trouv√© pour la session {session_id}")
                        
                        # Acquitter le message de la queue originale
                        channel.basic_ack(method_frame.delivery_tag)
                        
                        # Transf√©rer le message dans queue_chatbot
                        logger.info(f" Transfert du message vers {chatbot_queue_name}")
                        channel.basic_publish(
                            exchange='',
                            routing_key=chatbot_queue_name,
                            body=json.dumps(message),
                            properties=pika.BasicProperties(
                                delivery_mode=2  # Message persistant
                            )
                        )
                        
                        # Log du message complet
                        logger.info(f" Message de compl√©tion final pour la session {session_id}")
                        logger.info(json.dumps(message, indent=2))
                        
                        # Retourner le message complet
                        return json.dumps(message, indent=2)
                    
                    # Si pas le bon message, le remettre dans la queue
                    logger.info(f" Message ne correspondant pas √† la session {session_id}. Remis en queue.")
                    channel.basic_nack(method_frame.delivery_tag, requeue=True)
                
                except json.JSONDecodeError as e:
                    # Log de l'erreur d√©taill√©e
                    logger.error(f" Erreur de d√©codage JSON : {e}")
                    logger.error(f" Message brut re√ßu : {body}")
                    logger.error(f" Message nettoy√© : {message_str}")
                    
                    # Tenter un d√©codage plus permissif
                    try:
                        # Utiliser un d√©codeur JSON plus permissif
                        import ast
                        message = ast.literal_eval(body.decode('utf-8'))
                        
                        # Si le d√©codage r√©ussit, convertir en JSON
                        message_json = json.dumps(message)
                        logger.info(f" D√©codage r√©ussi avec ast.literal_eval : {message_json}")
                    except Exception as ast_error:
                        logger.error(f" √âchec du d√©codage avec ast.literal_eval : {ast_error}")
                    
                    channel.basic_nack(method_frame.delivery_tag, requeue=False)
                
                # Attendre un peu avant la prochaine v√©rification
                time.sleep(poll_interval)
            
            # Timeout atteint
            logger.warning(f" Timeout atteint pour la session {session_id}")
            return f"Timeout : pas de r√©ponse pour la session {session_id} dans le d√©lai imparti"
    
    except Exception as e:
        logger.error(f" Erreur lors de l'attente de la compl√©tion de t√¢che : {e}")
        return f"Erreur : {str(e)}"
    
    finally:
        logger.info(f" Fin de wait_for_task_completion pour la session {session_id}")


def enrich_query(self, query: str) -> str:
    """
    Enrichit la requ√™te utilisateur avec des informations pertinentes de la m√©moire

    Args:
        query (str): La requ√™te utilisateur originale

    Returns:
        str: La requ√™te enrichie
    """
    logger.info(f"üîç Enrichissement de la requ√™te : '{query}'")
    
    try:
        # R√©cup√©rer les informations pertinentes de la m√©moire
        relevant_info = self.memory.get_relevant(query)
        
        # Pr√©parer le contexte pour l'enrichissement
        context = "\n".join(relevant_info)
        
        # Utiliser l'API OpenAI pour enrichir la requ√™te
        response = self._openai_client.chat.completions.create(
            model=self.model_id,
            messages=[
                {
                    "role": "system", 
                    "content": """
                    Tu es un expert en enrichissement de requ√™tes.
                    Utilise le contexte fourni pour enrichir la requ√™te de mani√®re pertinente.
                    Garde l'essentiel de la requ√™te originale, mais ajoute des d√©tails ou pr√©cisions utiles.
                    """
                },
                {
                    "role": "user", 
                    "content": f"Requ√™te originale : {query}\n\nContexte :\n{context}"
                }
            ],
            max_tokens=150,
            temperature=0.7
        )
        
        enriched_query = response.choices[0].message.content.strip()
        logger.info(f"Requ√™te enrichie : '{enriched_query}'")
        
        return enriched_query
    
    except Exception as e:
        logger.error(f"Erreur lors de l'enrichissement de la requ√™te : {e}")
        return query  # Retourner la requ√™te originale en cas d'erreur



def get_user_proxy_agent(
    model_id: str = "gpt-4o-mini",
    user_id: Optional[str] = None,
    session_id: Optional[str] = None,
    debug_mode: bool = False,
    **kwargs
) -> Agent:
    """
    Cr√©er et configurer l'agent User Proxy.
    
    Args:
        model_id (str): Identifiant du mod√®le OpenAI √† utiliser
        user_id (Optional[str]): Identifiant de l'utilisateur
        session_id (Optional[str]): Identifiant de session
        debug_mode (bool): Mode d√©bogage
    
    Returns:
        Agent: Agent User Proxy configur√©
    """
    def submit_task(query: str) -> str:
        """
        Soumettre une t√¢che pour l'utilisateur courant
        
        Args:
            query (str): Requ√™te √† traiter
        
        Returns:
            str: R√©sultat de la soumission de t√¢che
        """
        # G√©n√©rer un nouvel identifiant de session
        current_session_id = str(uuid.uuid4())
        
        # Date courante
        date = datetime.now().isoformat()
        
        # Cr√©er un √©v√©nement pour signaler la compl√©tion
        task_completed = threading.Event()
        task_result = [None]
        
        def wait_for_completion():
            """
            Fonction pour attendre la compl√©tion en arri√®re-plan
            """
            try:
                result = wait_for_task_completion(session_id=current_session_id)
                task_result[0] = result
            except Exception as e:
                task_result[0] = f"Erreur : {str(e)}"
            finally:
                task_completed.set()
        
        # Log avant le d√©marrage du thread
        logger.info(f" Pr√©paration du thread de completion pour la t√¢che {current_session_id}")
        
        # D√©marrer le thread d'attente
        completion_thread = threading.Thread(
            target=wait_for_completion, 
            daemon=True  # Thread en arri√®re-plan
        )
        completion_thread.start()
        
        # Log apr√®s le d√©marrage du thread
        logger.info(f" Thread de completion d√©marr√© pour la t√¢che {current_session_id}")
        
        # V√©rification suppl√©mentaire de l'√©tat du thread
        if completion_thread.is_alive():
            logger.info(f" Thread de completion actif pour la t√¢che {current_session_id}")
        else:
            logger.warning(f" Le thread de completion ne semble pas actif pour la t√¢che {current_session_id}")
        
        query = get_user_preferences(query, user_id=user_id, db_url=db_url)

        # Envoi √† RabbitMQ
        send2RabbitMQ(
            query=query, 
            session_id=current_session_id, 
            user_id=user_id, 
            date=date
        )
        
        # Sauvegarde de la t√¢che
        save_user_proxy_task(
            task_id=current_session_id, 
            user_id=user_id or 'anonymous', 
            task_state='in_progress', 
            task_desc=query,
            task_create_on=datetime.fromisoformat(date)
        )
        
        # Log d'attente du message de compl√©tion
        logger.info(f"En attente du message de compl√©tion pour la session {current_session_id}")
        
        # Pr√©parer le message de retour attendu
        # message_retour = {
        #     "session_id": current_session_id,
        #     "status": "completed", 
        #     "query": query, 
        #     "result": "R√©sultat d√©taill√© de la t√¢che",
        #     "metadata": { 
        #         "sources": ["RabbitMQ"], 
        #         "timestamp": datetime.now().isoformat() 
        #     }
        # }
        
        # # Log du message de retour attendu
        # logger.info(f"Message de retour attendu : {json.dumps(message_retour, indent=2)}")
        
        # Retourner imm√©diatement un message indiquant que la t√¢che est en cours
        return json.dumps(f"T√¢che {current_session_id} en cours de traitement")
        
    
        # Configuration de l'agent
    agent_base = Agent(
        instructions=[
            "Tu es un agent intelligent avec deux modes de fonctionnement : transmission et traitement direct.",
            "",
            "- R√®gles de routage entre les 2 modes :",
            "  * Mode TRAITEMENT DIRECT :",
            "    - Pour les questions simples, g√©n√©rales ou relatives aux infos de l'utilisateur",
            "    - Exemples : salutations, pr√©f√©rences, informations basiques",
            "  * Mode TRANSMISSION DE REQU√äTE :",
            "    - Pour les demandes complexes n√©cessitant :",
            "      1. Recherche web",
            "      2. D√©composition de la t√¢che",
            "      3. Utilisation d'outils sp√©cifiques",
            "    - Exemples : analyse de donn√©es, recherches approfondies, t√¢ches multi-√©tapes",
            "MODE 1 : TRANSMISSION DE REQU√äTE",
            "- Objectif : Transmettre des requ√™tes complexes √† un syst√®me de traitement",
            "- Workflow :",
            "  1. R√©ceptionner une requ√™te n√©cessitant un traitement approfondi",
            "  2. G√©n√©rer un identifiant de session unique",
            "  3. Pr√©parer les m√©tadonn√©es :",
            "     * session_id : identifiant unique",
            "     * query : contenu original",
            "     * user_id : identifiant utilisateur",
            "     * timestamp : horodatage",
            "  4. Envoyer le message via RabbitMQ",
            "  5. Sauvegarder la t√¢che en base de donn√©es",
            "  6. Attendre le message de compl√©tion dans 'queue_retour_orchestrator'",
            "- Exemples de requ√™tes en mode transmission :",
            "  * 'Quel est le fonctionnement du moteur √©lectrique ?'",
            "  * 'R√©sume le dernier rapport technique'",
            "- En mode transmission, utiliser submit_task(query)",
            "", 
            "",
            "MODE 2 : TRAITEMENT DIRECT",
            "- Objectif : R√©pondre rapidement aux requ√™tes simples et g√©rer les interactions directes",
            "- Workflow pour le traitement direct :",
            "  1. Analyse la requ√™te de l'utilisateur",
            "  2. D√©termine si une r√©ponse directe est appropri√©e",
            "  3. Formule une r√©ponse adapt√©e en utilisant le style de communication d√©fini",
            "  4. Envoie la r√©ponse √† l'utilisateur",
            "- Style de communication :",
            "  * Sois sympathique et naturel dans tes r√©ponses",
            "  * Garde un ton l√©ger mais professionnel",
            "  * Utilise quelques emojis pour illustrer tes messages",
            "  * Important : En tant que LLM de l'agent User Proxy, tu es responsable de g√©n√©rer",
            "  * la r√©ponse finale √† l'utilisateur. Assure-toi que ta r√©ponse soit compl√®te,",
            "  * pertinente et respecte le style de communication demand√©.",
            "  * Sois sympathique et naturel dans tes r√©ponses",
            "  * Garde un ton l√©ger mais professionnel",
            "  * Utilise quelques emojis pour illustrer tes messages",
            "- Exemples de requ√™tes en mode direct :",
            "  * 'Quelles est la date de naissance de Henri 4 roi de France ?'",
            "  * 'Quelle est la capitale de la France ?'",
            "- En mode traitement direct, utilise au maximulm tes connaisances sur l'utuilisateur pour r√©pondre",
            "- Capacit√© √† comprendre et identifier des dates relatives :",
            "  * 'hier', 'aujourd'hui', 'demain'",
            "  * 'la semaine derni√®re', 'le mois prochain', 'l'ann√©e prochaine'",
            "  * 'dans 3 jours', 'il y a 2 semaines'",
            "  * 'le premier lundi du mois prochain'",
            "- Exemples de requ√™tes de date :",
            "  * 'Quelle est la date d'aujourd'hui ?'",
            "  * 'Donne-moi la date du dimanche dans 2 semaines'",
            "  * 'Quel jour serons-nous dans 10 jours ?'",
            "  * 'Quelle √©tait la date il y a 3 mois ?'",
            "- Exemple de calcul de date :",
            "  Si aujourd'hui nous sommes le mercredi 29 janvier 2025,",
            "  alors 'le deuxi√®me mardi du mois prochain' sera le mardi 11 f√©vrier 2025",
        ],
        model=OpenAIChat(
            model=model_id,
            temperature=0.3,  # Temp√©rature basse pour des r√©ponses plus d√©terministes
            max_tokens=500  # Limiter la longueur des r√©ponses
        ),
        tools=[
            submit_task,  # Nouvelle m√©thode de soumission de t√¢che
            # Conserver les autres outils existants si n√©cessaire
        ],
        debug_mode=debug_mode,
        agent_id="user_proxy_agent",
        user_id=user_id,
        session_id=session_id,
        name="User Proxy Agent",
        add_history_to_messages=True,
        num_history_responses=10,
        memory=AgentMemory(
            db=PgMemoryDb(table_name="user_proxy_memories", db_url=db_url),
            create_user_memories=True,
            update_user_memories_after_run=True,
            create_session_summary=True,
            update_session_summary_after_run=True,
        ),        
        storage=PgAgentStorage(table_name="user_proxy_sessions", db_url=db_url),
        **kwargs
    )
    
    return agent_base
