from typing import Optional
from phi.agent import Agent
from phi.model.openai import OpenAIChat
from phi.tools.python import PythonTools
from agents.settings import agent_settings
import os
import logging
from dotenv import load_dotenv
from db.url import get_db_url
from phi.storage.agent.postgres import PgAgentStorage
from phi.agent import AgentMemory
from phi.memory.db.postgres import PgMemoryDb
from utils.colored_logging import get_colored_logger
import httpx
import logging
from typing import Optional, Dict, Any, List

# Charger les variables d'environnement
load_dotenv()

# Configuration du logger
logger = get_colored_logger('agents.api_knowledge', 'APIKnowledgeAgent', level=logging.INFO)

db_url = get_db_url()

api_knowledge_storage = PgAgentStorage(table_name="api_knowledge_sessions", db_url=db_url)

# Configuration de l'URL de l'API LightRAG
API_LIGHTRAG_QUERY_URL = 'http://51.77.200.196:30080/query/'

def sync_query_lightrag_api(
    question: str, 
    user_id: str = "vinh", 
    mode: str = "hybrid", 
    vdb_filter: Optional[List[Dict]] = None, 
    limit: int = 10, 
    offset: int = 0
) -> str:
    """
    Interroger l'API de requ√™te de LightRAG de mani√®re synchrone
    
    Args:
        question (str): Question √† soumettre
        user_id (str, optional): ID de l'utilisateur. D√©faut √† "vinh".
        mode (str, optional): Mode de requ√™te. D√©faut √† "hybrid".
        vdb_filter (Optional[List[Dict]], optional): Filtres VDB. D√©faut √† None.
        limit (int, optional): Nombre maximum de r√©sultats. D√©faut √† 10.
        offset (int, optional): D√©calage des r√©sultats. D√©faut √† 0.
    
    Returns:
        str: Texte de r√©ponse de la requ√™te
    """

    # Log color√© pour indiquer la prise en charge de la demande
    logger.info("üìö Agent Connaissance API pr√™t √† interroger les bases de connaissances")
    
    # Utiliser une liste vide par d√©faut si vdb_filter est None
    if vdb_filter is None:
        vdb_filter = []

    try:
        # Configuration du client avec timeouts g√©n√©reux
        with httpx.Client(
            timeout=httpx.Timeout(
                connect=10.0,   # Timeout de connexion
                read=60.0,      # Timeout de lecture long
                write=60.0,     # Timeout d'√©criture long
                pool=60.0       # Timeout du pool de connexions
            ),
            follow_redirects=True,  # Activer le suivi des redirections
            max_redirects=3  # Limiter le nombre de redirections
        ) as client:
            # Pr√©parer la payload de requ√™te
            payload = {
                "question": question,
                "user_id": user_id,
                "mode": mode,
                "vdb_filter": vdb_filter,
                "limit": limit,
                "offset": offset
            }
            
            # Log d√©taill√© de la requ√™te
            logger.info(f" Requ√™te LightRAG - Question : {question}")
            logger.debug(f" Param√®tres de requ√™te : {payload}")
            
            try:
                response = client.post(
                    API_LIGHTRAG_QUERY_URL, 
                    json=payload
                )
                
                # Log d√©taill√© de la r√©ponse
                logger.debug(f" Requ√™te HTTP: {response.request.method} {response.request.url}")
                logger.debug(f" R√©ponse HTTP: {response.status_code} {response.reason_phrase}")
                
                # R√©cup√©rer et log du contenu de la r√©ponse
                response_content = response.json()
                logger.debug(f" Contenu de la r√©ponse : {response_content}")
                
                if response.status_code == 200 and response_content.get('status') == 'success':
                    # Extraire et retourner la r√©ponse textuelle
                    response_text = response_content.get('response', 'Aucune r√©ponse disponible')
                    
                    logger.debug(f" R√©ponse extraite : {response_text}")
                    return response_text
                else:
                    logger.error(f" √âchec de la requ√™te : {response.status_code} - {response.text}")
                    return "Erreur lors de la requ√™te √† l'API"
            
            except httpx.TimeoutException as e:
                logger.error(f" Timeout lors de la requ√™te : {e}")
                return "Timeout lors de la requ√™te"
            except ValueError as e:
                logger.error(f" Erreur de parsing JSON : {e}")
                return "Erreur de parsing de la r√©ponse"
    
    except Exception as e:
        logger.error(f" Erreur inattendue lors de la requ√™te √† l'API : {e}")
        import traceback
        logger.error(traceback.format_exc())
        return "Erreur inattendue lors de la requ√™te"

def get_api_knowledge_agent(
    user_id: Optional[str] = None,
    session_id: Optional[str] = None,
    debug_mode: bool = False
):
    """
    Cr√©er un agent de connaissance API utilisant LightRAG
    """
    from phi.agent import Agent
    from phi.model.openai import OpenAIChat
    from phi.tools.python import PythonTools
    from agents.settings import agent_settings

    # R√©cup√©rer l'URL de base de donn√©es (optionnel)
    if db_url:
        logger.debug(f"URL de base de donn√©es configur√©e : {db_url}")



    # Cr√©er l'agent de connaissance
    api_knowledge_agent = Agent(
        name="API Knowledge Agent",
        role="Agent sp√©cialis√© dans l'interrogation de bases de connaissances via LightRAG",
        model=OpenAIChat(
            id=agent_settings.gpt_4,
            max_tokens=agent_settings.default_max_completion_tokens,
            temperature=agent_settings.default_temperature,
        ),
        instructions=[
            "Tu es un agent expert dans l'interrogation de bases de connaissances structur√©es.",
            "Ton r√¥le est d'interpr√©ter pr√©cis√©ment les requ√™tes et de les traduire en requ√™tes API efficaces.",
            "Utilise la fonction sync_query_lightrag_api pour rechercher des informations.",
            "√âtapes de traitement :",
            "1. Analyse soigneusement la requ√™te re√ßue",
            "2. Utilise sync_query_lightrag_api pour obtenir les informations",
            "3. Si la requ√™te √©choue, fournis un message d'erreur clair",
            "4. Formate la r√©ponse de mani√®re lisible et concise",
            "",
            "Recommandations :",
            "- Adapte le mode de requ√™te selon le contexte",
            "- Limite le nombre de r√©sultats pour optimiser la r√©ponse",
            "- Priorise la pr√©cision et la pertinence des informations"
        ],
        tools=[
            PythonTools(),
            sync_query_lightrag_api
        ],
        show_tool_calls=True,
        debug_mode=debug_mode,
        user_id=user_id,
        session_id=session_id,
        markdown=True,
        stream=False  # D√©sactiver le streaming
    )

    return api_knowledge_agent

# Exemple d'utilisation
if __name__ == "__main__":
    test_query = "Qu'est-ce que l'intelligence artificielle ?"
    api_knowledge_agent = get_api_knowledge_agent()
    result = api_knowledge_agent.print_response(test_query)